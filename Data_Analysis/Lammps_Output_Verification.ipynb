{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T06:27:06.915262Z",
     "start_time": "2021-11-16T06:27:06.898838Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as net\n",
    "import lammps_logfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T02:11:51.076097Z",
     "start_time": "2021-05-20T02:11:50.965381Z"
    }
   },
   "source": [
    "# Save file with final configurations\n",
    "import sys\n",
    "f = []\n",
    "for i in range(100):\n",
    "    f.append([i+1,int(1),1.0,1.0,grains[i,2],grains[i,3], 0.0])\n",
    "data1 = np.array(f)\n",
    "np.savetxt('check.txt',data1,fmt='%i %i %1.1f %1.1f %1.4f %1.4f %1.4f')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T06:27:10.927931Z",
     "start_time": "2021-11-16T06:27:10.462017Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def set_size(width, fraction=1):\n",
    "    \"\"\" Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Document textwidth or columnwidth in pts\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim\n",
    "\n",
    "\n",
    "def freedman_diaconis(data, returnas=\"width\"):\n",
    "    \"\"\"\n",
    "    Use Freedman Diaconis rule to compute optimal histogram bin width. \n",
    "    ``returnas`` can be one of \"width\" or \"bins\", indicating whether\n",
    "    the bin width or number of bins should be returned respectively. \n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        One-dimensional array.\n",
    "\n",
    "    returnas: {\"width\", \"bins\"}\n",
    "        If \"width\", return the estimated width for each histogram bin. \n",
    "        If \"bins\", return the number of bins suggested by rule.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = np.asarray(data, dtype=np.float_)\n",
    "    IQR = stats.iqr(data, rng=(25, 75), scale=1.0, nan_policy=\"omit\")\n",
    "    if(IQR == 0 or np.isinf(data.max())):\n",
    "        # int(freedman_diaconis(data[data!=0], returnas=\"bins\")/(np.sum(data!= 0)/len(data)))\n",
    "        NBRBINS = -1\n",
    "        bw = -1\n",
    "    else:\n",
    "        N = data.size\n",
    "        bw = (2 * IQR) / np.power(N, 1/3)\n",
    "        datmin, datmax = data.min(), data.max()\n",
    "        datrng = datmax - datmin\n",
    "        NBRBINS = int((datrng / bw) + 1)\n",
    "    return(NBRBINS, bw)\n",
    "\n",
    "\n",
    "def plothist(arr, xlabel, file):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(500.484))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    array = np.copy(arr)\n",
    "    weights = 100*np.ones(len(array)) / len(array)\n",
    "\n",
    "    NBR_BINS, bw = freedman_diaconis(data=array, returnas=\"bins\")\n",
    "\n",
    "    mu = round(array.mean(), 4)\n",
    "    sigma = round(array.std(), 4)\n",
    "    max_ = round(np.max(array), 4)\n",
    "    min_ = round(np.min(array), 4)\n",
    "\n",
    "    if(NBR_BINS <= 0):\n",
    "        n, bins, patches = ax.hist(\n",
    "            array, weights=weights, histtype='stepfilled',range=[min(array),max(array)])\n",
    "    else:\n",
    "        n, bins, patches = ax.hist(\n",
    "            array, bins=NBR_BINS, weights=weights, histtype='stepfilled',range=[min(array),max(array)])\n",
    "        # xs = np.linspace(min(array), max(array), 1000)\n",
    "        # density = gaussian_kde(array)\n",
    "        # density.covariance_factor = lambda: 1\n",
    "        # density._compute_covariance()\n",
    "        # ax.plot(xs, bw*density(xs), '--')\n",
    "\n",
    "    ax.set_ylabel(\"% of Test images\")\n",
    "    ax.set_title('$\\mu$=' + str(mu) + ', $\\sigma$=' + str(sigma))\n",
    "    ax.axvline(mu, color='k', linestyle='dashed', linewidth=1)\n",
    "    plt.show()\n",
    "#     plt.savefig(file+\".png\", format='png',dpi=1000,bbox_inches='tight')\n",
    "#     plt.close(fig)\n",
    "\n",
    "def function_hist(a,NBR):\n",
    "\n",
    "    # 12 bins\n",
    "    ini = np.min(a)\n",
    "    final = np.max(a)\n",
    "    bins = np.linspace(ini, final, NBR+1)\n",
    "    hist = np.histogram(a, bins, density= True)\n",
    "    \n",
    "    return hist\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "def plothist_grid(arr, xlabel, file, ax):   \n",
    "    \n",
    "    mu = round(arr.mean(), 4)\n",
    "    sigma = round(arr.std(), 4)\n",
    "    max_ = round(np.max(arr), 4)\n",
    "    min_ = round(np.min(arr), 4)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"$Log_{10}(P_N)$\")\n",
    "    \n",
    "    array = np.copy(arr)\n",
    "    NBR_BINS, bw = freedman_diaconis(data=array, returnas=\"bins\")\n",
    "    hist = function_hist(array,1000+1)\n",
    "    bins = hist[1][:-1]\n",
    "    pdf = hist[0]\n",
    "    \n",
    "    kd = KernelDensity(kernel='gaussian', bandwidth=1).fit(arr.reshape(-1, 1))\n",
    "\n",
    "    # Plot the estimated densty\n",
    "    start = np.min(arr)  # Start of the range\n",
    "    end = np.max(arr)    # End of the range\n",
    "    N = 1000    # Number of evaluation points \n",
    "    step = (end - start) / (N - 1)  # Step size\n",
    "    x = np.linspace(start, end, N)[:, np.newaxis]  # Generate values in the range\n",
    "    # score_samples calculates log_density\n",
    "    kd_vals = kd.score_samples(x)\n",
    "    ax.plot(x, kd_vals,'r')\n",
    "#     ax.hist(array,NBR_BINS,density=True)\n",
    "#     kd_vals1 = kd.score_samples(arr.reshape(-1, 1))\n",
    "    ax.scatter(bins, np.log(pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T06:27:13.957408Z",
     "start_time": "2021-11-16T06:27:13.935029Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "def scale01(M):\n",
    "\n",
    "    New_M = np.zeros((M.shape))\n",
    "    MIN = np.min(M)\n",
    "    MAX = np.max(M)\n",
    "    for i in range(M.shape[0]):\n",
    "            M_ = M[i]\n",
    "            if (MAX == MIN):\n",
    "                New_M[i] = 0.0 * M_\n",
    "            else:\n",
    "                New_M[i] = (M_ - MIN) / (MAX - MIN)\n",
    "\n",
    "    return New_M\n",
    "\n",
    "import scipy\n",
    "def plothist(arr, xlabel, file, percentile):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=set_size(500.484))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    array = np.copy(arr)\n",
    "    weights = 100*np.ones(len(array)) / len(array)\n",
    "\n",
    "    NBR_BINS, bw = freedman_diaconis(data=array, returnas=\"bins\")\n",
    "\n",
    "    mu = round(array.mean(), 4)\n",
    "    sigma = round(array.std(), 4)\n",
    "    max_ = round(np.max(array), 4)\n",
    "    min_ = round(np.min(array), 4)\n",
    "    perc = round(np.percentile(array,percentile),4)\n",
    "\n",
    "    if(NBR_BINS <= 0):\n",
    "        n, bins, patches = ax.hist(\n",
    "            array, weights=weights, histtype='stepfilled',range=[min(array),max(array)],density=True)\n",
    "    else:\n",
    "        n, bins, patches = ax.hist(\n",
    "            array, bins=NBR_BINS, weights=weights, histtype='stepfilled',range=[min(array),max(array)])\n",
    "    \n",
    "    ax.set_ylabel(\"%\")\n",
    "    ax.set_title('$'+str(percentile)+'^{th}\\%$=' + str(perc))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.axvline(perc, color='r', linestyle='dashed', linewidth=1)\n",
    "    plt.show()\n",
    "    # plt.savefig(file+\".png\", format='png',dpi=1000,bbox_inches='tight')\n",
    "    # plt.close(fig)\n",
    "    # print(n.max())\n",
    "    # plt.plot(n,bins[:-1])\n",
    "    # plt.show()\n",
    "    \n",
    "def scale01(M):\n",
    "\n",
    "    New_M = np.zeros((M.shape))\n",
    "    MIN = np.min(M)\n",
    "    MAX = np.max(M)\n",
    "    for i in range(M.shape[0]):\n",
    "            M_ = M[i]\n",
    "            if (MAX == MIN):\n",
    "                New_M[i] = 0.0 * M_\n",
    "            else:\n",
    "                New_M[i] = (M_ - MIN) / (MAX - MIN)\n",
    "\n",
    "    return New_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Energy data per timestep\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T02:32:01.542935Z",
     "start_time": "2021-11-10T02:32:01.538448Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale(data):\n",
    "    data = data.reshape(-1,1)\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T17:53:06.633765Z",
     "start_time": "2021-11-15T17:53:06.502038Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(log.data_dict['v_p2'],label='press')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T19:23:51.573611Z",
     "start_time": "2021-11-15T19:23:51.418288Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# _dir = \"/media/ankit/A_SSD/PhD/Granular_project/LAMMPS/uniaxial/results/Hooke_H-wall_V-periodic_Particle-indent/0.01_0_1/\"\n",
    "\n",
    "_dir = \"/media/ankit/A_SSD/PhD/Granular_project/LAMMPS/uniaxial/Hooke/\"\n",
    "\n",
    "log = lammps_logfile.File(_dir+\"log.equil\")\n",
    "# log1 = lammps_logfile.File(_dir+\"log.deform\")\n",
    "\n",
    "# print(len(log.data_dict['Step']))\n",
    "print(len(log.data_dict['PotEng']))\n",
    "print(len(log.data_dict['KinEng']))\n",
    "print(len(log.data_dict['TotEng']))\n",
    "\n",
    "K1 = 0\n",
    "K2 = -1\n",
    "step = 1\n",
    "timestep = log.data_dict['v_t'][1]-log.data_dict['v_t'][0]\n",
    "plt.title('nve')\n",
    "plt.xlabel('seconds')\n",
    "plt.ylabel('Joules')\n",
    "\n",
    "t = log.data_dict['v_t'][K1:K2:step]\n",
    "KE = (log.data_dict['KinEng'][K1:K2:step])\n",
    "PE = (log.data_dict['PotEng'][K1:K2:step])\n",
    "TE = (log.data_dict['TotEng'][K1:K2:step])\n",
    "\n",
    "plt.plot(KE,label='KinEng_small')\n",
    "plt.plot(PE,label='PotEng')\n",
    "plt.plot(PE+KE,label='SumEng')\n",
    "# plt.plot(TE,label='TotEng')\n",
    "# plt.plot(log.data_dict['v_iforce'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T06:08:21.245473Z",
     "start_time": "2021-11-15T06:08:19.751320Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(Y,ylabel,label):\n",
    "    plt.plot(Y, label=label)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.savefig(label+\".png\", format='png',dpi=1000,bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "plot(KE,'Energy','KinEng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading LAMMPS data Each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T20:10:11.678355Z",
     "start_time": "2021-10-24T20:10:04.571428Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# _dir = '/home/ankit/Desktop/My_local_work/project_temp/Granular_project/results/LJ/'\n",
    "# _dir = \"/home/ankit/Desktop/My_local_work/project_temp/Granular_project/LAMMPS/reference/\"\n",
    "_dir = \"/media/ankit/A_SSD/PhD/Granular_project/LAMMPS/uniaxial/\"\n",
    "file1 = open(_dir+'dump.neigh', 'r')\n",
    "lines = [line.rstrip() for line in file1]\n",
    "\n",
    "file2 = open(_dir+'visualize.du', 'r')\n",
    "lines2 = [line.rstrip() for line in file2]\n",
    "\n",
    "num_start = 0\n",
    "graph_list = []\n",
    "frame = 0\n",
    "for num1, line in enumerate(lines, 0):\n",
    "    if 'ITEM' in line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            curr_timestep1 = int(lines[num1+1])\n",
    "        if 'ITEM: NUMBER OF ENTRIES' in line:\n",
    "            num_entries = int(lines[num1+1])\n",
    "            table = []\n",
    "        if 'ITEM: ENTRIES' in line:\n",
    "            x = lines[num1+1:num1+1+num_entries]\n",
    "            for i in range(len(x)):\n",
    "                table.append(list(map(float, x[i].split(\" \"))))\n",
    "                \n",
    "            pairwise = np.array(table.copy())\n",
    "            for num, line in enumerate(lines2, num_start):\n",
    "                if 'ITEM' in line:\n",
    "                    if 'ITEM: TIMESTEP' in line:\n",
    "                        curr_timestep2 = int(lines2[num+1])\n",
    "                        print(num, curr_timestep2, curr_timestep1)\n",
    "                    if 'ITEM: NUMBER OF ATOMS' in line:\n",
    "                        num_entries2 = int(lines2[num+1])\n",
    "                        table = []\n",
    "                    if 'ITEM: ATOMS' in line:\n",
    "                        x = lines2[num+1:num+1+num_entries2]\n",
    "                        for i in range(len(x)):\n",
    "                            table.append(list(map(float, x[i].split(\" \"))))\n",
    "                                            \n",
    "                        grains = np.array(table.copy())\n",
    "                        grains = grains[grains[:, 0].argsort()]\n",
    "                        num_start = num+1+num_entries2\n",
    "                        break;\n",
    "                                   \n",
    "            Granular_network=net.Graph()\n",
    "            nx,ny = grains.shape\n",
    "            for i in range(nx):\n",
    "                Granular_network.add_node(grains[i,0],pos=(grains[i,2],grains[i,3]))\n",
    "\n",
    "            if(num_entries):\n",
    "                # force chain 50 percentile definition\n",
    "                cForces = pairwise[:,5:8]\n",
    "                cForceMags = np.sqrt(np.sum(cForces**2,axis=1))\n",
    "                cForceMax = np.percentile(cForceMags,50)\n",
    "                mask = cForceMags > cForceMax\n",
    "                nMask = len(np.where(mask)[0]) #number of grains satisfying condition above \n",
    "                if(nMask):\n",
    "                    cForces[mask] = [cForces[mask][i]/cForceMags[mask][i]*cForceMax for i in range(nMask)] #set biggest forces = 95% \n",
    "                    cForcesNormalized = cForces/cForceMax #normalize all forces by 50th% force \n",
    "                    cForcesNormalizedMags = np.linalg.norm(cForcesNormalized,axis=1) #get magnitude of normalized forces\n",
    "\n",
    "                    # Normalize the contact force\n",
    "                    v = cForcesNormalizedMags\n",
    "                    v = (v - v.min()) / (v.max() - v.min())\n",
    "\n",
    "                nx,ny = pairwise.shape\n",
    "                for i in range(nx):\n",
    "                    id1 = int(pairwise[i,1])-1\n",
    "                    id2 = int(pairwise[i,2])-1\n",
    "                    dist = np.sqrt((grains[id1,2]-grains[id2,2])**2 + (grains[id1,3]-grains[id2,3])**2)\n",
    "                    if(mask[i] and dist<=1):\n",
    "                        Granular_network.add_edge(pairwise[i,1], pairwise[i,2],weight=1)\n",
    "#                     if(dist<=7):\n",
    "#                         Granular_network.add_edge(pairwise[i,1], pairwise[i,2],weight=1)                        \n",
    "\n",
    "            graph_list.append(Granular_network.copy())\n",
    "#             nx.draw(Granular_network,pos,width=weights-np.mean(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T20:10:18.693964Z",
     "start_time": "2021-10-24T20:10:16.829323Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "print(len(graph_list))\n",
    "fps = 1\n",
    "# fig = plt.figure()\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "def init():\n",
    "    plt.clf()\n",
    "    return fig,ax\n",
    "\n",
    "def update(it):\n",
    "    G = graph_list[it]\n",
    "    edges = G.edges()\n",
    "    weights = [G[u][v]['weight'] for u,v in edges]\n",
    "    pos=net.get_node_attributes(G,'pos')\n",
    "    plt.cla()\n",
    "#     net.draw(G,pos,width=weights,edge_color=weights,edge_cmap=plt.cm.YlOrRd)\n",
    "    net.draw(G,pos,width=weights,node_size=1)\n",
    "    return fig\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, update,init_func = init, frames=list(range(len(graph_list))))\n",
    "ani.save(_dir+'indent.mp4', fps=fps, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T06:27:57.322089Z",
     "start_time": "2021-11-16T06:27:56.436903Z"
    }
   },
   "outputs": [],
   "source": [
    "# _dir = \"/media/ankit/A_SSD/PhD/Granular_project/LAMMPS/uniaxial/Hooke/\"\n",
    "_dir = \"/home/ankit/Desktop/\"\n",
    "file1 = open(_dir+'neigh.deform', 'r')\n",
    "lines = [line.rstrip() for line in file1]\n",
    "\n",
    "for num, line in enumerate(lines, 0):\n",
    "    if 'ITEM' in line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            curr_timestep = int(lines[num+1])\n",
    "        if 'ITEM: NUMBER OF ENTRIES' in line:\n",
    "            num_entries = int(lines[num+1])\n",
    "            table = []\n",
    "        if 'ITEM: ENTRIES' in line:\n",
    "            x = lines[num+1:num+1+num_entries]\n",
    "            for i in range(len(x)):\n",
    "                table.append(list(map(float, x[i].split(\" \"))))\n",
    "            break;\n",
    "           \n",
    "print(curr_timestep)\n",
    "pairwise0 = np.array(table.copy())\n",
    "            \n",
    "file2 = open(_dir+'visualize.deform', 'r')\n",
    "lines = [line.rstrip() for line in file2]\n",
    "\n",
    "for num, line in enumerate(lines, 0):\n",
    "    if 'ITEM' in line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            curr_timestep = int(lines[num+1])\n",
    "        if 'ITEM: NUMBER OF ATOMS' in line:\n",
    "            num_entries = int(lines[num+1])\n",
    "            table = []\n",
    "        if 'ITEM: ATOMS' in line:\n",
    "            x = lines[num+1:num+1+num_entries]\n",
    "            for i in range(len(x)):\n",
    "                table.append(list(map(float, x[i].split(\" \"))))\n",
    "                \n",
    "            break;\n",
    "                \n",
    "grains0 = np.array(table.copy())\n",
    "grains0 = grains0[grains0[:,1] != 3]\n",
    "grains0 = grains0[grains0[:, 0].argsort()]\n",
    "print(curr_timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T06:28:36.519532Z",
     "start_time": "2021-11-16T06:28:35.735625Z"
    }
   },
   "outputs": [],
   "source": [
    "# _dir = \"/media/ankit/A_SSD/PhD/Granular_project/LAMMPS/\"\n",
    "_dir = \"/home/ankit/Desktop/\"\n",
    "# log = lammps_logfile.File(_dir+\"log.deform\")\n",
    "# STEP = int(log.data_dict['Step'][-1])\n",
    "file1 = open(_dir+'neigh.deform', 'r')\n",
    "lines = [line.rstrip() for line in file1]\n",
    "STEP = 5100000\n",
    "\n",
    "for num, line in enumerate(lines, 0):\n",
    "    if 'ITEM' in line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            curr_timestep = int(lines[num+1])\n",
    "        if 'ITEM: NUMBER OF ENTRIES' in line:\n",
    "            num_entries = int(lines[num+1])\n",
    "            table = []\n",
    "        if 'ITEM: ENTRIES' in line:\n",
    "            if(curr_timestep!=STEP):\n",
    "                continue\n",
    "            x = lines[num+1:num+1+num_entries]\n",
    "            for i in range(len(x)):\n",
    "                table.append(list(map(float, x[i].split(\" \"))))\n",
    "            \n",
    "            if(curr_timestep==STEP):\n",
    "                break;\n",
    "           \n",
    "print(curr_timestep)\n",
    "pairwise = np.array(table.copy())\n",
    "            \n",
    "file2 = open(_dir+'visualize.deform', 'r')\n",
    "lines = [line.rstrip() for line in file2]\n",
    "\n",
    "for num, line in enumerate(lines, 0):\n",
    "    if 'ITEM' in line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            curr_timestep = int(lines[num+1])\n",
    "        if 'ITEM: NUMBER OF ATOMS' in line:\n",
    "            num_entries = int(lines[num+1])\n",
    "            table = []\n",
    "        if 'ITEM: ATOMS' in line:\n",
    "            if(curr_timestep!=STEP):\n",
    "                continue\n",
    "            x = lines[num+1:num+1+num_entries]\n",
    "            for i in range(len(x)):\n",
    "                table.append(list(map(float, x[i].split(\" \"))))\n",
    "            \n",
    "            if(curr_timestep==STEP):\n",
    "                break;   \n",
    "                \n",
    "print(curr_timestep)\n",
    "grains = np.array(table.copy())\n",
    "grains = grains[grains[:,1] != 3]\n",
    "grains = grains[grains[:, 0].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T20:15:59.525084Z",
     "start_time": "2021-11-14T20:15:59.503802Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "def store_data_in_hdffile_2(name_, data, hf):\n",
    "#     if (name_ not in hf):\n",
    "#         hf.create_dataset(name_, (np.append(1, data.shape)),\n",
    "#                           'float64')\n",
    "\n",
    "    n, p = data.shape\n",
    "    hf[name_] = data.reshape(1,n,p)\n",
    "    \n",
    "with h5py.File(_dir+'data.h5', 'a') as f:\n",
    "    store_data_in_hdffile_2('grains0',grains0,f)\n",
    "    store_data_in_hdffile_2('pairwise0',pairwise0,f)\n",
    "    store_data_in_hdffile_2('grains',grains,f)\n",
    "    store_data_in_hdffile_2('pairwise',pairwise,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing Positional Disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T20:26:16.861294Z",
     "start_time": "2021-10-24T20:26:16.512622Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "Fs = 1000\n",
    "T = 1/Fs\n",
    "x = np.arange(0, 50, T)\n",
    "N = len(x)\n",
    "y = np.zeros(len(x))\n",
    "\n",
    "for xx in np.unique(np.sort(grains[:,3])):\n",
    "    y[x == xx] = 1\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "plt.show()\n",
    "yf = fft(y)\n",
    "xf = fftfreq(N, T)[:N//2]\n",
    "\n",
    "plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "np.unique(np.sort(grains[:,3])), 1/.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T16:41:37.851570Z",
     "start_time": "2021-10-21T16:41:37.434086Z"
    }
   },
   "outputs": [],
   "source": [
    "def comb(T):\n",
    "    result = np.zeros(len(t))\n",
    "    result[::int(Fs*T)] = 1\n",
    "    return result\n",
    "\n",
    "def ft(x):\n",
    "    \"\"\"Calculate the Fourier transform of a given signal x\"\"\"\n",
    "    return np.fft.fftshift(np.fft.fft(x)) * Fs / len(x)\n",
    "\n",
    "Fs = 1000\n",
    "t = np.arange(0, 2, 1/Fs)\n",
    "f = np.linspace(-Fs/2, Fs/2, len(t), endpoint=False)\n",
    "\n",
    "T1 = 0.1\n",
    "C_T1 = comb(T1)\n",
    "T2 = 0.05\n",
    "C_T2 = comb(T2)\n",
    "\n",
    "plt.subplot(221); plt.plot(t, C_T1)\n",
    "plt.subplot(222); plt.plot(f, abs(ft(C_T1)*T1))\n",
    "\n",
    "plt.subplot(223); plt.plot(t, C_T2)\n",
    "plt.subplot(224); plt.plot(f, abs(ft(C_T2)*T2))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T20:26:33.975876Z",
     "start_time": "2021-10-24T20:26:31.525465Z"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.stats import RipleysKEstimator\n",
    "\n",
    "z1 = np.random.uniform(low=5, high=10, size=(100, 2))\n",
    "z2 = grains[:,3:5]\n",
    "Kest = RipleysKEstimator(area=25, x_max=10, y_max=10, x_min=5, y_min=5)\n",
    "# plt.plot(z1,\"*\")\n",
    "# plt.plot(z1[:,0],z1[:,1],\".\")\n",
    "# plt.plot(z2[:,0],z2[:,1],\".\")\n",
    "r = np.linspace(0, 2.5, 100)\n",
    "plt.plot(r, Kest(data=z2, radii=r, mode='none'), color='red', ls='--',label=r'$K_{un}$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "83px",
    "width": "277.333px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
